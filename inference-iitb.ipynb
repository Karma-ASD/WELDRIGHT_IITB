{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#imports\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler as std\nfrom sklearn.decomposition import PCA\nimport os\nimport gc\nimport sys\nimport seaborn as sns\nimport torch \nimport torch.nn as nn\nimport keras\nimport datetime\nfrom tqdm import tqdm \nimport gc \nimport pickle as p\nfrom tensorflow.keras import initializers","metadata":{"execution":{"iopub.status.busy":"2022-12-04T13:36:25.129122Z","iopub.execute_input":"2022-12-04T13:36:25.129502Z","iopub.status.idle":"2022-12-04T13:36:34.204914Z","shell.execute_reply.started":"2022-12-04T13:36:25.129471Z","shell.execute_reply":"2022-12-04T13:36:34.203697Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def the_model():\n    x_input =keras.layers.Input(shape=(cfg.num_rows, cfg.num_cols))\n    x1 = keras.layers.Bidirectional(keras.layers.LSTM(units=256, return_sequences=True))(x_input)\n    x2 = keras.layers.Bidirectional(keras.layers.LSTM(units=128, return_sequences=True))(x1)\n    z1 = keras.layers.Bidirectional(keras.layers.GRU(units=64, return_sequences=True))(x1)\n    c = keras.layers.Concatenate(axis=2)([x2, z1])\n#     x3 = keras.layers.Bidirectional(keras.layers.LSTM(units=256, return_sequences=True))(c)\n#     x30=keras.layers.Bidirectional(keras.layers.LSTM(units=256,return_sequences=True))(x1)\n#     c1=keras.layers.Concatenate(axis=2)([x3,x30])\n    x4 = keras.layers.GlobalMaxPooling1D()(c)#(c1)\n    #x41=keras.layers.Dense(units=32,activation=\"relu\")(x4)\n    x411=keras.layers.Dense(units=16,activation=\"relu\", kernel_initializer=initializers.RandomNormal(stddev=0.01),\n    bias_initializer=initializers.Zeros())(x4)\n    x42=keras.layers.Dropout(0.05)(x411)\n    x_output = keras.layers.Dense(1, activation='sigmoid')(x42)\n    model = keras.models.Model(inputs=x_input, outputs=x_output, name='lstm_model')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-04T13:36:34.206606Z","iopub.execute_input":"2022-12-04T13:36:34.207181Z","iopub.status.idle":"2022-12-04T13:36:34.217467Z","shell.execute_reply.started":"2022-12-04T13:36:34.207137Z","shell.execute_reply":"2022-12-04T13:36:34.215515Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model(\".\")","metadata":{"execution":{"iopub.status.busy":"2022-12-04T13:48:24.771124Z","iopub.execute_input":"2022-12-04T13:48:24.771544Z","iopub.status.idle":"2022-12-04T13:48:24.777187Z","shell.execute_reply.started":"2022-12-04T13:48:24.771508Z","shell.execute_reply":"2022-12-04T13:48:24.776061Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/cleaned-weld-right-data/Test_data.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Production.unique(),df[\"Order Operation No\"].unique()\nle = preprocessing.LabelEncoder()\ncol=[\"Production\",\"Order Operation No\"]\n\ndf[col[0]]=df[col[0]].values.astype(np.str_)\ndf[col[1]]=df[col[1]].values.astype(np.str_)\ndf[col[0]] = le.fit_transform(df[col[0]].values)\ndf[col[1]] = le.fit_transform(df[col[1]].values)\ndf.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ndomain specific features\n\"\"\"\ndef feature1(df):\n    #df[\"Voltage\"]=df[\"Voltage\"]\n    df[\"Power\"]=(df[\"Current\"])*((df[\"Voltage\"])+1)\n    df[\"Delta_Temperature\"]= df[\"Job Temp\"]-df[\"Temperature\"]\n    df[\"Resistance\"]=(df[\"Voltage\"]+1)/(df[\"Current\"])\n    df[\"Delta_Charge\"]=(df[\"Current\"])*(1/1000)*df[\"Delta_Time\"]\n    df[\"Alpha\"]=df[\"Humidity\"]/df[\"Delta_Temperature\"]\n    df[\"Heat\"]=df[\"Power\"]*df[\"Delta_Time\"]*(1/1000)\n    return df\n\"\"\"\nLag features\n\"\"\"\ndef lag(df):\n    coll=[\"Power\",\"Delta_Time\",\"Delta_Temperature\",\"Alpha\",\"Heat\",'Current','Humidity','Flow','Job Temp']\n    for i in coll:\n        temp=[]\n        for j in range(len(df[i])):\n            if j==0 :\n                temp.append(0)\n            else:\n                temp.append(df[i].iloc[j] - df[i].iloc[j-1] )\n        df[f\"lag_{i}\"]=temp\n    return df\n\"\"\")\npca , ica \n\"\"\"\ndef pca_originals(df):\n    \"\"\"\n     to make our ml model stable\n        \n    \"\"\"\n    names=coll=[\"Current\",\"Humidity\",\"Temperature\",\"Flow\",\"Job Temp\",\"Voltage\"]\n    pca= PCA(n_components=None)\n    #df[coll]=std_transform(df[coll],coll)\n    df[[\"Pca_\"+i for i in coll]]= pca.fit_transform(df[names])\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    def time_feature(df):\n        \"\"\"\n        gives time in milli second\n        1st = time\n        2nd = delta_time\n        hr : min : sec : m_sec\n        \n        \"\"\"\n        a=df.Time\n        b=df.Date\n        a1=[]\n        a2=[]\n        current=0\n        for i in tqdm(range(len(df))):\n            if current == b[i]:\n                t=a[i].split(\":\")\n            elif i == 0 or current!=b[i]:\n                current=b[i]\n                t=[0,0,0,0]\n            a1.append(int(t[0])*60*60*1000+int(t[1])*60*1000+int(t[2])*1000+int(t[3]))# hr min sec mili sec\n            if i == 0:\n                a2.append(0)\n            else:\n                a2.append(a1[i]-a1[i-1])\n        return a1,a2\n    \n    def remove_feature(df,names):\n        \"\"\"\n        remove 1_to_1 features\n        \n        \"\"\"\n        cols= df.columns\n        for i in names:\n            del df[i]\n        return df\n    \n    def std_transform(df,names):\n        \"\"\"\n        standardize values \n        (before pca)\n        \n        \"\"\"\n        scale=std()\n        df[names]=scale.fit_transform(df[names])\n        return df\n    \n    def divi(df,name):\n        \"\"\"\n        type - dictionary \n        keys - unique entries in column\n        (to be used with employee code \"specifically\")\n        \n        \"\"\"\n        df_code= df.groupby(name)\n        df1= {}\n        \n        for i in df_code:\n            df1[i[0]] = i[1]\n        return df1\n    \n    def label(df):\n        defs=df.Defect.values\n        defs=defs!=\"No Defect\"\n        defs=defs*1\n        df.Defect=defs\n        return df\n        \n    def prep_training(df, history = 60):\n        snips1=[]\n        for i in tqdm(range( len(df)) ):\n            if df.iloc[i].Defect == 1 and i >= history:\n                temp=df.iloc[i-history+1:i+1]\n                temp=remove_feature(temp,names=cols[:1])\n                temp=remove_feature(temp,names=[\"Defect\",\"label\"])\n                snips1.append(temp)\n        snips0=[]\n        \"\"\"\n        startification of entries\n        \"\"\"\n        for i in tqdm(range( len(df)) ):\n            if df.iloc[i].Defect == 0 and i >= history and len(snips0)<len(snips1)*2:\n                temp=df.iloc[i-history+1:i+1]\n                temp=remove_feature(temp,names=cols[:1])\n                temp=remove_feature(temp,names=[\"Defect\",\"label\"])\n                snips0.append(temp)\n        snips=[snips0,snips1]\n        return snips","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"            \ndef transform1(df):\n    #1st convert time\n    (a,b)=time_feature(df)\n    df[\"Time\"]=a\n    df[\"Delta_Time\"]=b\n    df=feature1(df)\n    df=lag(df)\n    #df=pca_originals(df)\n    print(df.head())\n    print(1)\n    #2nd remove useless cols-> machine / date /  \n    col=[\"Machine\",\"Date\"]\n    df=remove_feature(df,col)\n    print(2)\n    #3rd correct labels\n    df=label(df)\n    print(3)\n    #4th 9 workers 9 dfs\n    df=divi(df,name=df.columns[0])\n    keys=df.keys()\n    \"\"\"\n    output={int->id : grouped df}\n    \"\"\"\n    print(4)\n    #5th std all dfs\n    for i in tqdm(df):\n        df[i]=prep_training(df[i])\n\n    print(5)\n    gc.collect()\n    return df\n\"\"\"\nfirst approach 40 ki history with subtle gradient for transition from 0 to the first 1 \nthen adapt the curve\n\"\"\"\n    \ndef cols_update(df):\n    return [i for i in df.columns]\ndff=df\ncols=cols_update(dff)\ndft=transform1(dff)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=dft","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in tqdm(data):\n    typee=np.float\n#     print(s[0],type(data[i][0][0]))\n#     print(data[0][0][0].shape)\n    temp0=np.array(data[i][0]).astype(typee)\n    temp1=np.array(data[i][1]).astype(typee)\n    ln_1=len(data[i][1])\n    ln_0=(ln_1)\n    ln_0=int(ln_0)\n    x=np.concatenate((temp0[:ln_1],temp1))\n    data[i]=[x,y]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=[]\nfor i in data:\n    x.extend(data[i][0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=model.predict(x)","metadata":{},"execution_count":null,"outputs":[]}]}